{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv                                                                                      \n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def isNumber(word):\n",
    "    if word >= u'\\U00010100' and word <= u'\\U0001013f':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "place_names = {}\n",
    "transaction_words = {}\n",
    "transaction_signs = {}\n",
    "numbers = {}\n",
    "commodities = {}\n",
    "from_suffix = {}\n",
    "adjectives = {}\n",
    "to_prefix = {}\n",
    "fractions = {}\n",
    "weights = {}\n",
    "logograms = {}\n",
    "words_in_linearb = {}\n",
    "word_types = [(place_names, \"060-place-names.txt\", \"place name\", 0, 1),\n",
    "        (transaction_words, \"060-transaction-words.txt\", \"transaction term\", 0, 1),\n",
    "        (numbers, \"050-numbers.csv\", \"number\", 0, 1),\n",
    "        (fractions, \"065-fractions.txt\", \"fraction\", 0, 0),\n",
    "        (numbers, \"065-fractions.txt\", \"number\", 0, 0),\n",
    "        (weights, \"065-weights.txt\", \"weight\", 0, 0),\n",
    "        (logograms, \"065-logograms.txt\", \"logogram\", 0, 0),\n",
    "        (commodities, \"060-commodities.txt\", \"commodity\", 0, 1),\n",
    "        (from_suffix, \"060-from-suffix.txt\", \"uses from suffix (-TE/-TI)\", 0, 1),\n",
    "        (adjectives, \"060-adjectives.txt\", \"adjective for placename\", 0, 1),\n",
    "        (to_prefix, \"060-to-prefix.txt\", \"uses to prefix (I-/J-)\", 0, 1),\n",
    "        (words_in_linearb, \"135-identical-words-in-linearb.txt\", \"word also in linear b\", 0, 1),\n",
    "        (transaction_signs, \"160-transaction-signs.txt\", \"transaction sign\", 0, 1),\n",
    "        ]\n",
    "for word_type in word_types:\n",
    "    dictionary = word_type[0]\n",
    "    input_file = open(\"../../../LinearA-Original/\" + word_type[1], 'r')\n",
    "    while True:\n",
    "        line = input_file.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line_array = line.strip().split('\\t')\n",
    "        dictionary[line_array[word_type[3]]] = line_array[word_type[4]]\n",
    "\n",
    "json_file = open('../../../LinearA-Original/150-metadata-template.js')\n",
    "data = json.load(json_file)\n",
    "inscriptions = data[\"metadata\"]\n",
    "\n",
    "def isHeadWord(word, original_word, no_of_words):\n",
    "    if no_of_words == 1:\n",
    "        return False\n",
    "    if index:\n",
    "        return False\n",
    "    if original_word.startswith(u'\\U0001076b'):\n",
    "        return False\n",
    "    if original_word == u'\\U00010101':\n",
    "        return False\n",
    "    if word == \"—\":\n",
    "        return False\n",
    "    if word.isnumeric():\n",
    "        return False\n",
    "    return True;\n",
    "\n",
    "def assignNumberToPreviousWord(word, word_tags, index, prev_word_tag, prev_original_word):\n",
    "    if word not in numbers:\n",
    "        return False\n",
    "    if not index:\n",
    "        return False\n",
    "    if word == u'\\U00010101':\n",
    "        return False\n",
    "    if word.startswith(u'\\U0001076b'):\n",
    "        return False\n",
    "    cleaned_prev_original_word = prev_original_word.replace(u'\\U0001076b', \"\")\n",
    "    if cleaned_prev_original_word in numbers:\n",
    "        return False\n",
    "    if prev_original_word.endswith(u'\\U0001076b'):\n",
    "        return False\n",
    "    if prev_original_word == \"\\n\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def shouldIncludeWord(word):\n",
    "    if word in numbers:\n",
    "        return False\n",
    "    if u'\\U00010101' in word:\n",
    "        return False\n",
    "    if word == \"—\":\n",
    "        return False\n",
    "    if word == \"\":\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def wordRepeatedInInscription(word_tags, word):\n",
    "    if not shouldIncludeWord(word):\n",
    "        return False\n",
    "\n",
    "    words = list(map(lambda x: x[\"word\"].replace(u'\\U0001076b', \"\"), word_tags))\n",
    "    if words.count(word) > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "word_find_spots = {}\n",
    "def addFindSpot(name, word):\n",
    "    if not shouldIncludeWord(word):\n",
    "        return\n",
    "    find_spot = name[:2]\n",
    "    if word not in word_find_spots:\n",
    "        word_find_spots[word] = [find_spot]\n",
    "        return\n",
    "    word_find_spots[word].append(find_spot)\n",
    "\n",
    "for inscription in inscriptions:\n",
    "    for tags in inscription[\"tagsForWords\"]:\n",
    "        word = tags[\"word\"]\n",
    "        word = word.replace(u'\\U0001076b', \"\")\n",
    "        addFindSpot(inscription[\"name\"], word)\n",
    "\n",
    "locations = {}\n",
    "locations[\"ZA\"] =\"Zakros\"          \n",
    "locations[\"PK\"] =\"Palaikastro\"  \n",
    "locations[\"PE\"] =\"Petras\"  \n",
    "locations[\"SY\"] =\"Syme\" \n",
    "locations[\"PS\"] =\"Pseira\" \n",
    "locations[\"MA\" ] =\"Malia\" \n",
    "locations[\"AR\"] =\"Arkhalkhori\" \n",
    "locations[\"IO\"] =\"Iouktas\" \n",
    "locations[\"KN\"] =\"Knossos\" \n",
    "locations[\"TY\"] =\"Tylissos\"  \n",
    "locations[\"PH\"] =\"Phaistos\"  \n",
    "locations[\"HT\"] =\"Haghia Triada\"  \n",
    "locations[\"AP\"] =\"Apodoulou\"  \n",
    "locations[\"KH\"] =\"Kharnia\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the disbursement transactions where commodoties are relatively ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main transaction tablets where commodities are ordered\n",
    "\n",
    "transaction_tablets = [\"ARKH3a\", \"ARKH3b\", \"HT2\", \"HT100\", \"HT101\", \n",
    "        \"HT114a\", \"HT116a\", \"HT116b\", \"HT12\", \"HT121\", \"HT125a\", \"HT125b\",\n",
    "        \"HT129\", \"HT131a\", \"HT131b\", \"HT137\", \"HT139\", \"HT14\", \"HT18\", \"HT21\",\n",
    "        \"HT23a\", \"HT23b\", \"HT27a\", \"HT27b\", \"HT28a\", \"HT28b\", \"HT30\", \"HT30\",\n",
    "        \"HT32\", \"HT33\", \"HT34\", \"HT35\", \"HT44a\", \"HT50a\", \"HT58\", \"HT90\",\n",
    "        \"HT91\", \"HT96b\", \"HT99a\", \"KH5\", \"KH8\", \"KH9\", \"KH9\", \"KH11\", \"KH21\",\n",
    "        \"KH55\", \"KH61\", \"KNZb35\", \"TY3a\", \"ZA18a\", \"ZA6a\", \"ZA6b\", \"ZA11a\"]\n",
    "\n",
    "new_inscriptions = []\n",
    "for old_inscription in inscriptions:\n",
    "    inscription = old_inscription.copy()\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "    if inscription[\"name\"] not in transaction_tablets:\n",
    "        continue\n",
    "\n",
    "    inscription[\"transactions\"] = []\n",
    "    commodityID = 0\n",
    "    transactionID = 0\n",
    "    for index, word_tag in enumerate(word_tags):\n",
    "        word = word_tag[\"transliteratedWord\"]\n",
    "        original_word = word_tag[\"word\"]\n",
    "        if \"tags\" in word_tag:\n",
    "            del word_tag[\"tags\"]\n",
    "\n",
    "        tags = []\n",
    "        if word == \"\\n\":\n",
    "            continue\n",
    "\n",
    "        if original_word == u'\\U0001076b':\n",
    "            tags.append(\"lacuna\")\n",
    "        if original_word.startswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at start\")\n",
    "        if original_word.endswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at end\")\n",
    "        if u'\\U00010101' in original_word:\n",
    "            tags.append(\"word separator\")\n",
    "        if original_word == \"—\":\n",
    "            tags.append(\"dividing line\")\n",
    "\n",
    "        cleaned_word = word.replace(u'\\U0001076b', \"\")\n",
    "        cleaned_original_word = original_word.replace(u'\\U0001076b', \"\")\n",
    "        for word_type in word_types:\n",
    "            dictionary = word_type[0]\n",
    "            annotation = word_type[2]\n",
    "            if cleaned_word in dictionary or cleaned_original_word in dictionary:\n",
    "                if not annotation in tags:\n",
    "                    tags.append(annotation)\n",
    "\n",
    "        if (len(cleaned_word) > 1 and not \"word separator\" in tags\n",
    "            and word != '—' and word !=  u'\\U0001076b'\n",
    "            and not 'logogram' in tags\n",
    "            and not 'commodity' in tags\n",
    "            and not \"number\" in tags and not \"fraction\" in tags):\n",
    "            tags.append(\"word\")\n",
    "\n",
    "        prev_word_tag = word_tags[index - 1]\n",
    "        prev_original_word = prev_word_tag[\"word\"]\n",
    "        if assignNumberToPreviousWord(cleaned_original_word, word_tags, index,\n",
    "                prev_word_tag, prev_original_word):\n",
    "            commodityID += 1\n",
    "            prev_word_tag[\"description\"] = \"commodity\"\n",
    "            prev_word_tag[\"commodityID\"] = commodityID\n",
    "        if \"number\" in tags:\n",
    "            word_tag[\"commodityID\"] = commodityID\n",
    "            word_tag[\"description\"] = \"quantity\"\n",
    "\n",
    "        if \"word\" in tags:\n",
    "            word_tag[\"description\"] = \"recipient\"\n",
    "            commodityID = 0\n",
    "            transactionID += 1\n",
    "        full_transaction_id = inscription[\"name\"] + '-' + str(transactionID)\n",
    "        word_tag[\"transactionID\"] = full_transaction_id\n",
    "        if full_transaction_id not in inscription[\"transactions\"]:\n",
    "            transaction_entry = {\"description\" : \"sender\",\n",
    "                                 \"transliteratedWord\" : locations[inscription[\"name\"][:2]] + \" Magazine\",\n",
    "                                \"transactionID\" : full_transaction_id}\n",
    "            if transaction_entry not in inscription[\"transactions\"]:\n",
    "                inscription[\"transactions\"].append(transaction_entry)\n",
    "\n",
    "    inscription[\"words\"] = inscription.pop(\"tagsForWords\")\n",
    "    output_file = open(inscription[\"name\"] + \".js\", \"w\")\n",
    "    output_file.write(json.dumps(inscription, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    new_inscriptions.append(inscription)\n",
    "\n",
    "transactions = {}\n",
    "transactions[\"disbursement-transactions\"] =  new_inscriptions\n",
    "\n",
    "#output_file = open(\"040-disbursement-transactions.js\", \"w\")\n",
    "#output_file.write(json.dumps(transactions, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "#print(json.dumps(transactions, sort_keys=True, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find some candidate tablets meeting certain patterns\n",
    "\n",
    "Here we're looking for patterns where the quantity is assigned to the recipient rather than the commodity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HT1 matches but file already exists\n",
      "HT3 matches but file already exists\n",
      "HT6a matches but file already exists\n",
      "HT6b matches but file already exists\n",
      "HT7a matches but file already exists\n",
      "HT8a matches but file already exists\n",
      "HT8b matches but file already exists\n",
      "HT9a matches but file already exists\n",
      "HT9b matches but file already exists\n",
      "HT10a matches but file already exists\n",
      "HT10b matches but file already exists\n",
      "HT11a written\n",
      "HT11b written\n",
      "HT13 matches but file already exists\n",
      "HT15 matches but file already exists\n",
      "HT16 written\n",
      "HT17 matches but file already exists\n",
      "HT19 matches but file already exists\n",
      "HT20 written\n",
      "HT24a written\n",
      "HT25a matches but file already exists\n",
      "HT25b written\n",
      "HT29 matches but file already exists\n",
      "HT31 matches but file already exists\n",
      "HT38 written\n",
      "HT39 written\n",
      "HT40 matches but file already exists\n",
      "HT42+59 matches but file already exists\n",
      "HT45b written\n",
      "HT49a written\n",
      "HT51a matches but file already exists\n",
      "HT60 written\n",
      "HT69 matches but file already exists\n",
      "HT82 written\n",
      "HT85a matches but file already exists\n",
      "HT85b matches but file already exists\n",
      "HT86a matches but file already exists\n",
      "HT86b matches but file already exists\n",
      "HT87 matches but file already exists\n",
      "HT88 written\n",
      "HT92 matches but file already exists\n",
      "HT93a written\n",
      "HT94a matches but file already exists\n",
      "HT94b matches but file already exists\n",
      "HT95a matches but file already exists\n",
      "HT95b matches but file already exists\n",
      "HT96a written\n",
      "HT97a written\n",
      "HT98a written\n",
      "HT99b written\n",
      "HT102 matches but file already exists\n",
      "HT103 written\n",
      "HT104 matches but file already exists\n",
      "HT106 written\n",
      "HT108 written\n",
      "HT110b written\n",
      "HT115a written\n",
      "HT115b matches but file already exists\n",
      "HT117a written\n",
      "HT119 written\n",
      "HT120 matches but file already exists\n",
      "HT122a written\n",
      "HT122b written\n",
      "HT123+124a written\n",
      "HT123+124b written\n",
      "HT126a matches but file already exists\n",
      "HT127b written\n",
      "HT128a matches but file already exists\n",
      "HT130 written\n",
      "HT133 matches but file already exists\n",
      "HT140 written\n",
      "HT154a written\n",
      "HTZd157+156 written\n",
      "KH4 written\n",
      "KH6 written\n",
      "KH7a written\n",
      "KH7b written\n",
      "KH12 written\n",
      "KH14 written\n",
      "KH15 written\n",
      "KH20 written\n",
      "KH25 written\n",
      "KH26 written\n",
      "KH54 written\n",
      "KH58 written\n",
      "KH60 written\n",
      "KH63 written\n",
      "KH73 written\n",
      "KH75 written\n",
      "KH76 written\n",
      "KH84 written\n",
      "KH88 matches but file already exists\n",
      "KH91 written\n",
      "KN2 written\n",
      "KN28a written\n",
      "MA4a written\n",
      "MA6a written\n",
      "MA6c written\n",
      "MA10b written\n",
      "PE1 written\n",
      "PE2 written\n",
      "PH2 written\n",
      "PH3b written\n",
      "PH8a written\n",
      "PH(?)31b matches but file already exists\n",
      "PK3 written\n",
      "THEtab.4 written\n",
      "THEZb5 written\n",
      "TY2 written\n",
      "TY3b written\n",
      "ZA1b matches but file already exists\n",
      "ZA4a matches but file already exists\n",
      "ZA5a matches but file already exists\n",
      "ZA5b matches but file already exists\n",
      "ZA8 matches but file already exists\n",
      "ZA10a written\n",
      "ZA10b written\n",
      "ZA11b written\n",
      "ZA12a written\n",
      "ZA12b written\n",
      "ZA14 written\n",
      "ZA15a matches but file already exists\n",
      "ZA15b written\n",
      "ZA20 written\n",
      "ZA26a matches but file already exists\n",
      "ARKH2 matches but file already exists\n",
      "ARKH4b matches but file already exists\n"
     ]
    }
   ],
   "source": [
    "# Find some candidate tablets meeting certain patterns\n",
    "\n",
    "transaction_tablets = [\"ARKH3a\", \"ARKH3b\", \"HT2\", \"HT100\", \"HT101\", \n",
    "        \"HT114a\", \"HT116a\", \"HT116b\", \"HT12\", \"HT121\", \"HT125a\", \"HT125b\",\n",
    "        \"HT129\", \"HT131a\", \"HT131b\", \"HT137\", \"HT139\", \"HT14\", \"HT18\", \"HT21\",\n",
    "        \"HT23a\", \"HT23b\", \"HT27a\", \"HT27b\", \"HT28a\", \"HT28b\", \"HT30\", \"HT30\",\n",
    "        \"HT32\", \"HT33\", \"HT34\", \"HT35\", \"HT44a\", \"HT50a\", \"HT58\", \"HT90\",\n",
    "        \"HT91\", \"HT96b\", \"HT99a\", \"KH5\", \"KH8\", \"KH9\", \"KH9\", \"KH11\", \"KH21\",\n",
    "        \"KH55\", \"KH61\", \"KNZb35\", \"TY3a\", \"ZA18a\", \"ZA6a\", \"ZA6b\", \"ZA11a\"]\n",
    "\n",
    "\n",
    "def wordsContainPattern(current_pattern):\n",
    "    patterns = [\n",
    "                [\"head word\", \"commodity\", \"word\", \"number\", \"word\", \"number\"],\n",
    "                [\"transaction term\", \"commodity\", \"word\", \"number\", \"word\", \"number\"],\n",
    "                [\"word\", \"word\", \"word\", \"number\", \"word\", \"number\"],\n",
    "                [\"word\", \"word\", \"commodity\", \"number\"],\n",
    "                [\"word\", \"logogram\", \"word\", \"number\"],\n",
    "                [\"word\", \"logogram\", \"number\", \"logogram\", \"number\"],\n",
    "                [\"word\", \"number\", \"word\", \"number\", \"word\", \"number\"],\n",
    "                [\"word\", \"number\", \"word\", \"number\", \"number\", \"word\", \"number\"],\n",
    "                [\"word\", \"number\", \"word\", \"number\", \"number\", \"word\", \"number\"],\n",
    "                [\"logogram\", \"number\", \"logogram\", \"number\"],\n",
    "               ]\n",
    "    to_skip = [\"word separator\"]\n",
    "    for pattern in patterns:\n",
    "        matching_pattern = []\n",
    "        for tags in current_pattern:\n",
    "            if \"word separator\" in tags:\n",
    "                continue\n",
    "            index = len(matching_pattern)\n",
    "            if pattern[index] in tags:\n",
    "                matching_pattern.append(pattern[index])\n",
    "            else:\n",
    "                matching_pattern = []\n",
    "            if len(matching_pattern) == len(pattern):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "new_inscriptions = []\n",
    "for old_inscription in inscriptions:\n",
    "    inscription = old_inscription.copy()\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "    \n",
    "    # ignore tablets we've already covered\n",
    "    if inscription[\"name\"] in transaction_tablets:\n",
    "        continue\n",
    "        \n",
    "    inscription[\"transactions\"] = {}\n",
    "    commodityID = 0\n",
    "    transactionID = 0\n",
    "    current_pattern = []\n",
    "    \n",
    "    for index, word_tag in enumerate(word_tags):\n",
    "        word = word_tag[\"transliteratedWord\"]\n",
    "        original_word = word_tag[\"word\"]\n",
    "        if \"tags\" in word_tag:\n",
    "            del word_tag[\"tags\"]\n",
    "\n",
    "        tags = []\n",
    "        if word == \"\\n\":\n",
    "            continue\n",
    "\n",
    "        if original_word == u'\\U0001076b':\n",
    "            tags.append(\"lacuna\")\n",
    "        if original_word.startswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at start\")\n",
    "        if original_word.endswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at end\")\n",
    "        if u'\\U00010101' in original_word:\n",
    "            tags.append(\"word separator\")\n",
    "        if original_word == \"—\":\n",
    "            tags.append(\"dividing line\")\n",
    "\n",
    "        cleaned_word = word.replace(u'\\U0001076b', \"\")\n",
    "        cleaned_original_word = original_word.replace(u'\\U0001076b', \"\")\n",
    "        for word_type in word_types:\n",
    "            dictionary = word_type[0]\n",
    "            annotation = word_type[2]\n",
    "            if cleaned_word in dictionary or cleaned_original_word in dictionary:\n",
    "                if not annotation in tags:\n",
    "                    tags.append(annotation)\n",
    "\n",
    "        if (len(cleaned_word) > 1 and not \"word separator\" in tags\n",
    "            and word != '—' and word !=  u'\\U0001076b'\n",
    "            and not 'logogram' in tags\n",
    "            and not 'commodity' in tags\n",
    "            and not \"number\" in tags and not \"fraction\" in tags):\n",
    "            tags.append(\"word\")\n",
    "\n",
    "        prev_word_tag = word_tags[index - 1]\n",
    "        prev_original_word = prev_word_tag[\"word\"]\n",
    "        if assignNumberToPreviousWord(cleaned_original_word, word_tags, index,\n",
    "                prev_word_tag, prev_original_word):\n",
    "            prev_word_tag[\"description\"] = \"recipient\"\n",
    "            prev_word_tag[\"commodityID\"] = commodityID\n",
    "        if \"number\" in tags:\n",
    "            word_tag[\"commodityID\"] = commodityID\n",
    "            word_tag[\"description\"] = \"quantity\"\n",
    "\n",
    "        if \"commodity\" in tags:\n",
    "            commodityID += 1\n",
    "            word_tag[\"commodityID\"] = commodityID\n",
    "            word_tag[\"description\"] = \"commodity\"\n",
    "\n",
    "        if \"word\" in tags:\n",
    "            word_tag[\"description\"] = \"sender\"\n",
    "            transactionID += 1\n",
    "        full_transaction_id = inscription[\"name\"] + '-' + str(transactionID)\n",
    "        word_tag[\"transactionID\"] = full_transaction_id\n",
    "        current_pattern += [tags]\n",
    "  \n",
    "    inscription[\"words\"] = inscription.pop(\"tagsForWords\")\n",
    "    \n",
    "    if not wordsContainPattern(current_pattern):\n",
    "        continue\n",
    "    #print(json.dumps(inscription, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    if os.path.isfile(\"./final/\" + inscription[\"name\"] + '.js'):\n",
    "        print(inscription[\"name\"], \"matches but file already exists\")\n",
    "        continue\n",
    "    if os.path.isfile(\"./ignore/\" + inscription[\"name\"] + '.js'):\n",
    "        print(inscription[\"name\"], \"matches but file already exists\")\n",
    "        continue\n",
    "    print(inscription[\"name\"], \"written\")\n",
    "\n",
    "    output_file = open(inscription[\"name\"] + \".js\", \"w\")\n",
    "    output_file.write(json.dumps(inscription, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    output_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create templates for some missing tablets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HT3 matches but file already exists\n",
      "HT7b written\n",
      "HT11b written\n",
      "HT16 written\n",
      "HT20 written\n",
      "HT24a written\n",
      "HT24b written\n",
      "HT25a matches but file already exists\n",
      "HT26a written\n",
      "HT26b written\n",
      "HT31 matches but file already exists\n",
      "HT36 written\n",
      "HT39 matches but file already exists\n",
      "HT43 written\n",
      "HT62+73 written\n",
      "HT63 written\n",
      "HT86b written\n",
      "HT89 written\n",
      "HT93a written\n",
      "HT98a written\n",
      "HT103 written\n",
      "HT105 written\n",
      "HT110a written\n",
      "HT123+124a written\n",
      "HT123+124b written\n",
      "HT127b written\n",
      "HT130 matches but file already exists\n",
      "HT132 written\n",
      "HT140 matches but file already exists\n",
      "HT146 written\n",
      "KH4 matches but file already exists\n",
      "KH6 matches but file already exists\n",
      "KH7a written\n",
      "KH7b written\n",
      "PE1 written\n",
      "PE2 written\n",
      "TY2 written\n",
      "TY3b written\n",
      "ZA1a written\n",
      "ZA7a written\n",
      "ZA9 written\n",
      "ZA10a written\n",
      "ZA10b written\n",
      "ZA11b written\n",
      "ZA14 matches but file already exists\n",
      "ZA15b written\n",
      "ZA20 written\n",
      "ARKH5 written\n"
     ]
    }
   ],
   "source": [
    "# Find some candidate tablets meeting certain patterns\n",
    "\n",
    "transaction_tablets = ['ZA14', 'HT127b', 'HT146', 'HT25a', 'HT3', 'HT39', 'HT63',\n",
    "                       'HT98a', 'ZA20', 'ZA7a', 'ZA10a', 'ZA10b', 'PE2', 'HT130',\n",
    "                       'HT24b', 'TY2', 'HT105', 'HT123+124a', 'HT132', 'HT20', 'ZA1a',\n",
    "                       'ZA9', 'ZA15b', 'KH6', 'KH7a', 'KH7b', 'TY3b', 'ARKH5', 'KH4',\n",
    "                       'HT31', 'HT43', 'PE1', 'ZA11b', 'HT16', 'HT24a', 'HT123+124b', \n",
    "                       'HT7b', 'HT26a', 'HT11b', 'HT103', 'HT110a', 'HT26b', 'HT36',\n",
    "                       'HT62+73', 'HT89', 'HT93a', 'HT140', 'HT86b']\n",
    "\n",
    "\n",
    "new_inscriptions = []\n",
    "for old_inscription in inscriptions:\n",
    "    inscription = old_inscription.copy()\n",
    "    word_tags = inscription[\"tagsForWords\"]\n",
    "    \n",
    "    # ignore tablets we're not interested in\n",
    "    if inscription[\"name\"] not in transaction_tablets:\n",
    "        continue\n",
    "        \n",
    "    inscription[\"transactions\"] = []\n",
    "    commodityID = 0\n",
    "    transactionID = 0\n",
    "    current_pattern = []\n",
    "    \n",
    "    for index, word_tag in enumerate(word_tags):\n",
    "        word = word_tag[\"transliteratedWord\"]\n",
    "        original_word = word_tag[\"word\"]\n",
    "        if \"tags\" in word_tag:\n",
    "            del word_tag[\"tags\"]\n",
    "\n",
    "        tags = []\n",
    "        if word == \"\\n\":\n",
    "            continue\n",
    "\n",
    "        if original_word == u'\\U0001076b':\n",
    "            tags.append(\"lacuna\")\n",
    "        if original_word.startswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at start\")\n",
    "        if original_word.endswith(u'\\U0001076b'):\n",
    "            tags.append(\"lacuna at end\")\n",
    "        if u'\\U00010101' in original_word:\n",
    "            tags.append(\"word separator\")\n",
    "        if original_word == \"—\":\n",
    "            tags.append(\"dividing line\")\n",
    "\n",
    "        cleaned_word = word.replace(u'\\U0001076b', \"\")\n",
    "        cleaned_original_word = original_word.replace(u'\\U0001076b', \"\")\n",
    "        for word_type in word_types:\n",
    "            dictionary = word_type[0]\n",
    "            annotation = word_type[2]\n",
    "            if cleaned_word in dictionary or cleaned_original_word in dictionary:\n",
    "                if not annotation in tags:\n",
    "                    tags.append(annotation)\n",
    "\n",
    "        if (len(cleaned_word) > 1 and not \"word separator\" in tags\n",
    "            and word != '—' and word !=  u'\\U0001076b'\n",
    "            and not 'logogram' in tags\n",
    "            and not 'commodity' in tags\n",
    "            and not \"number\" in tags and not \"fraction\" in tags):\n",
    "            tags.append(\"word\")\n",
    "\n",
    "        prev_word_tag = word_tags[index - 1]\n",
    "        prev_original_word = prev_word_tag[\"word\"]\n",
    "        if assignNumberToPreviousWord(cleaned_original_word, word_tags, index,\n",
    "                prev_word_tag, prev_original_word):\n",
    "            prev_word_tag[\"description\"] = \"recipient\"\n",
    "            prev_word_tag[\"commodityID\"] = commodityID\n",
    "        if \"number\" in tags:\n",
    "            word_tag[\"commodityID\"] = commodityID\n",
    "            word_tag[\"description\"] = \"quantity\"\n",
    "\n",
    "        if \"commodity\" in tags:\n",
    "            commodityID += 1\n",
    "            word_tag[\"commodityID\"] = commodityID\n",
    "            word_tag[\"description\"] = \"commodity\"\n",
    "\n",
    "        if \"word\" in tags:\n",
    "            word_tag[\"description\"] = \"sender\"\n",
    "            transactionID += 1\n",
    "        full_transaction_id = inscription[\"name\"] + '-' + str(transactionID)\n",
    "        word_tag[\"transactionID\"] = full_transaction_id\n",
    "        current_pattern += [tags]\n",
    "  \n",
    "    inscription[\"words\"] = inscription.pop(\"tagsForWords\")\n",
    "    \n",
    "    #print(json.dumps(inscription, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    if os.path.isfile(\"./final/\" + inscription[\"name\"] + '.js'):\n",
    "        print(inscription[\"name\"], \"matches but file already exists\")\n",
    "        continue\n",
    "    if os.path.isfile(\"./ignore/\" + inscription[\"name\"] + '.js'):\n",
    "        print(inscription[\"name\"], \"matches but file already exists\")\n",
    "        continue\n",
    "    print(inscription[\"name\"], \"written\")\n",
    "\n",
    "    output_file = open(inscription[\"name\"] + \".js\", \"w\")\n",
    "    output_file.write(json.dumps(inscription, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "    output_file.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write out a template file for the selected inscription\n",
    "name = \"HT146\"\n",
    "output_file = open(name + \".js\", \"w\")\n",
    "output_file.write(json.dumps([{\"name\": name,\n",
    "                              \"transactions\":[],\n",
    "                              \"words\": x[\"tagsForWords\"] }\n",
    "                              for x in inscriptions if x[\"name\"] == name]\n",
    "                             , sort_keys=True, indent=4, ensure_ascii=False))\n",
    "output_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write out the transaction files to the site directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "inputdir = \"./final/\"\n",
    "output_file = open(\"../transactions.js\", \"w\")\n",
    "output_file.write(\"var transactions = [\")\n",
    "for subdir, dirs, files in os.walk(inputdir):\n",
    "    for file in files:\n",
    "        if file[-2:] != \"js\":\n",
    "            continue\n",
    "        json_file = open(subdir + os.sep + file).read()\n",
    "        output_file.write(json_file)\n",
    "        output_file.write(',')\n",
    "output_file.write(\"];\")\n",
    "output_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
